{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["! pip install pyannote.audio\n","! git clone https://github.com/pyannote/AMI-diarization-setup.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:03:56.141694Z","iopub.status.busy":"2024-03-25T02:03:56.141378Z","iopub.status.idle":"2024-03-25T02:04:08.536933Z","shell.execute_reply":"2024-03-25T02:04:08.535853Z","shell.execute_reply.started":"2024-03-25T02:03:56.141664Z"},"trusted":true},"outputs":[],"source":["! mkdir /kaggle/working/voxconverse\n","! mkdir /kaggle/working/voxconverse/wav\n","! mkdir /kaggle/working/voxconverse/wav/train\n","! mkdir /kaggle/working/voxconverse/wav/dev\n","! mkdir /kaggle/working/voxconverse/wav/test\n","! mkdir /kaggle/working/voxconverse/rttm\n","! mkdir /kaggle/working/voxconverse/rttm/train\n","! mkdir /kaggle/working/voxconverse/rttm/dev\n","! mkdir /kaggle/working/voxconverse/rttm/test\n","! mkdir /kaggle/working/voxconverse/uem\n","! mkdir /kaggle/working/voxconverse/uem/train\n","! mkdir /kaggle/working/voxconverse/uem/dev\n","! mkdir /kaggle/working/voxconverse/uem/test"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:06:43.722269Z","iopub.status.busy":"2024-03-25T02:06:43.721864Z","iopub.status.idle":"2024-03-25T02:06:43.783230Z","shell.execute_reply":"2024-03-25T02:06:43.782419Z","shell.execute_reply.started":"2024-03-25T02:06:43.722216Z"},"trusted":true},"outputs":[],"source":["import os \n","dir_name = \"/kaggle/input/voxconverse-rttm/voxconverse-master/dev/\"\n","\n","filenames_train_dev =  [file.split('.')[0] for file in os.listdir(dir_name)]\n","filenames_train = filenames_train_dev[:int(0.7*len(filenames_train_dev))]\n","filenames_dev = filenames_train_dev[len(filenames_train):]\n","filenames_test = [file.split('.')[0] for file in os.listdir(\"/kaggle/input/voxconverse-rttm/voxconverse-master/test\")]\n","\n","\n","with open(f\"/kaggle/working/voxconverse/train.speakers.txt\", 'w') as f:\n","        f.write('\\n'.join(filenames_train))\n","\n","with open(f\"/kaggle/working/voxconverse/dev.speakers.txt\", 'w') as f:\n","    f.write('\\n'.join(filenames_dev))\n","\n","with open(f\"/kaggle/working/voxconverse/test.speakers.txt\", 'w') as f:\n","    f.write('\\n'.join(filenames_test))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:06:46.262976Z","iopub.status.busy":"2024-03-25T02:06:46.262574Z","iopub.status.idle":"2024-03-25T02:07:24.592405Z","shell.execute_reply":"2024-03-25T02:07:24.591336Z","shell.execute_reply.started":"2024-03-25T02:06:46.262944Z"},"trusted":true},"outputs":[],"source":["! cp /kaggle/input/voxconverse-rttm/voxconverse-master/test/* /kaggle/working/voxconverse/rttm/test\n","! cp /kaggle/input/voxconverse-dataset/voxconverse_test_wav/voxconverse_test_wav/* /kaggle/working/voxconverse/wav/test"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:07:24.594830Z","iopub.status.busy":"2024-03-25T02:07:24.594526Z","iopub.status.idle":"2024-03-25T02:07:33.919499Z","shell.execute_reply":"2024-03-25T02:07:33.918208Z","shell.execute_reply.started":"2024-03-25T02:07:24.594802Z"},"trusted":true},"outputs":[],"source":["! cp /kaggle/input/voxconverse-rttm/voxconverse-master/dev/* /kaggle/working/voxconverse/rttm/dev\n","! cp /kaggle/input/voxconverse-dataset/voxconverse_dev_wav/audio/* /kaggle/working/voxconverse/wav/dev"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:07:33.921748Z","iopub.status.busy":"2024-03-25T02:07:33.921345Z","iopub.status.idle":"2024-03-25T02:07:33.941200Z","shell.execute_reply":"2024-03-25T02:07:33.940499Z","shell.execute_reply.started":"2024-03-25T02:07:33.921708Z"},"trusted":true},"outputs":[],"source":["import shutil\n","\n","def move_files(source_dir, destination_dir, filenames_train):\n","    for file_name in filenames_train:\n","        source_file_path = os.path.join(source_dir, file_name)\n","        destination_file_path = os.path.join(destination_dir, file_name)\n","        shutil.move(source_file_path, destination_file_path)\n","\n","    \n","    \n","source_dir = \"/kaggle/working/voxconverse/rttm/dev\"\n","destination_dir = \"/kaggle/working/voxconverse/rttm/train\"\n","move_files(source_dir, destination_dir, [file + '.rttm' for file in filenames_train])\n","\n","               \n","source_dir = \"/kaggle/working/voxconverse/wav/dev\"\n","destination_dir = \"/kaggle/working/voxconverse/wav/train\"\n","move_files(source_dir, destination_dir, [file + '.wav' for file in filenames_train])"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:07:33.943366Z","iopub.status.busy":"2024-03-25T02:07:33.943104Z","iopub.status.idle":"2024-03-25T02:07:34.883855Z","shell.execute_reply":"2024-03-25T02:07:34.883049Z","shell.execute_reply.started":"2024-03-25T02:07:33.943344Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","def process_rttm_file(input_file, name):\n","    filename = input_file.split('/')[-1].split('.')[0]\n","    result = [filename, \"1\",  \"0.000\", \"\"]\n","    sum_1 = 0\n","    sum_2 = 0\n","    with open(input_file, 'r') as f:\n","        for line in f:\n","            parts = line.strip().split()\n","            sum_1 += float(parts[3])\n","            sum_2 += float(parts[4])\n","    \n","    result[-1]=str(sum_2)\n","    \n","    output_file = f\"/kaggle/working/voxconverse/uem/{name}/{filename}.uem\"\n","    with open(output_file, 'w') as f:\n","        f.write(' '.join(result))\n","    \n","\n","for filename in [file + '.rttm' for file in filenames_train]:\n","    file_path = os.path.join(\"/kaggle/working/voxconverse/rttm/train/\", filename)\n","    process_rttm_file(file_path, \"train\")\n","\n","for filename in [file + '.rttm' for file in filenames_dev]:\n","    file_path = os.path.join(\"/kaggle/working/voxconverse/rttm/dev/\", filename)\n","    process_rttm_file(file_path, \"dev\")\n","\n","for filename in [file + '.rttm' for file in filenames_test]:\n","    file_path = os.path.join(\"/kaggle/working/voxconverse/rttm/test/\", filename)\n","    process_rttm_file(file_path, \"test\")\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:13:45.803106Z","iopub.status.busy":"2024-03-25T02:13:45.802150Z","iopub.status.idle":"2024-03-25T02:13:45.808186Z","shell.execute_reply":"2024-03-25T02:13:45.807013Z","shell.execute_reply.started":"2024-03-25T02:13:45.803069Z"},"trusted":true},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","\n","import torch\n","from pyannote.audio import Pipeline\n","from pyannote.database import registry, FileFinder\n","from pyannote.metrics.diarization import DiarizationErrorRate"]},{"cell_type":"code","execution_count":56,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:20:20.385971Z","iopub.status.busy":"2024-03-25T02:20:20.385168Z","iopub.status.idle":"2024-03-25T02:20:20.392068Z","shell.execute_reply":"2024-03-25T02:20:20.391115Z","shell.execute_reply.started":"2024-03-25T02:20:20.385939Z"},"trusted":true},"outputs":[],"source":["config = \"\"\"Databases:\n","    # tell pyannote.database where to find AMI wav files.\n","    # {uri} is a placeholder for the session name (eg. ES2004c).\n","    # you might need to update this line to fit your own setup.\n","    VoxCeleb: \n","    - /kaggle/working/voxconverse/wav/train/{uri}.wav \n","    - /kaggle/working/voxconverse/wav/dev/{uri}.wav \n","    - /kaggle/working/voxconverse/wav/test/{uri}.wav \n","\n","Protocols: \n","    VoxCeleb: \n","        SpeakerDiarization: \n","            only_words:  \n","                train: \n","                    uri: /kaggle/working/voxconverse/train.speakers.txt \n","                    annotation: /kaggle/working/voxconverse/rttm/train/{uri}.rttm \n","                    annotated:  /kaggle/working/voxconverse/uem/train/{uri}.uem \n","                dev:  \n","                    uri: /kaggle/working/voxconverse/dev.speakers.txt \n","                    annotation: /kaggle/working/voxconverse/rttm/dev/{uri}.rttm \n","                    annotated:  /kaggle/working/voxconverse/uem/dev/{uri}.uem       \n","                test: \n","                    uri: /kaggle/working/voxconverse/test.speakers.txt \n","                    annotation: /kaggle/working/voxconverse/rttm/test/{uri}.rttm \n","                    annotated: /kaggle/working/voxconverse/uem/test/{uri}.uem \n","\"\"\"\n","\n","file_path = \"/kaggle/working/AMI-diarization-setup/pyannote/database3.yml\" \n","\n","with open(file_path, 'w') as file:\n","    file.write(config)"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:14:05.135941Z","iopub.status.busy":"2024-03-25T02:14:05.135117Z","iopub.status.idle":"2024-03-25T02:14:05.146070Z","shell.execute_reply":"2024-03-25T02:14:05.145143Z","shell.execute_reply.started":"2024-03-25T02:14:05.135910Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["'VoxCeleb.SpeakerDiarization.only_words' found in /kaggle/working/AMI-diarization-setup/pyannote/database3.yml does not define the 'scope' of speaker labels (file, database, or global). Setting it to 'file'.\n"]}],"source":["registry.load_database(\"/kaggle/working/AMI-diarization-setup/pyannote/database3.yml\")\n","preprocessors = {\"audio\": FileFinder()}\n","dataset = registry.get_protocol('VoxCeleb.SpeakerDiarization.only_words', preprocessors=preprocessors)"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:14:07.492978Z","iopub.status.busy":"2024-03-25T02:14:07.492606Z","iopub.status.idle":"2024-03-25T02:14:16.595528Z","shell.execute_reply":"2024-03-25T02:14:16.594404Z","shell.execute_reply.started":"2024-03-25T02:14:07.492950Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Protocol VoxCeleb.SpeakerDiarization.only_words does not precompute the output of torchaudio.info(): adding a 'torchaudio.info' preprocessor for you to speed up dataloaders. See pyannote.database documentation on how to do that yourself.\n"]}],"source":["from pyannote.audio import Model\n","from pyannote.audio.tasks import Segmentation\n","from types import MethodType\n","from torch.optim import Adam\n","from pytorch_lightning.callbacks import (\n","    EarlyStopping,\n","    ModelCheckpoint,\n","    RichProgressBar,\n",")\n","\n","model = Model.from_pretrained(\"pyannote/segmentation-3.0\", use_auth_token=True).cuda()\n","\n","task = Segmentation(\n","    dataset, \n","    duration=model.specifications.duration, \n","    max_num_speakers=len(model.specifications.classes), \n","    batch_size=32,\n","    num_workers=8, \n","    loss=\"bce\", \n","    vad_loss=\"bce\"\n",")\n","\n","model.task = task\n","model.prepare_data()\n","model.setup()"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-03-25T02:14:16.598019Z","iopub.status.busy":"2024-03-25T02:14:16.597605Z","iopub.status.idle":"2024-03-25T02:14:16.962836Z","shell.execute_reply":"2024-03-25T02:14:16.961288Z","shell.execute_reply.started":"2024-03-25T02:14:16.597981Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efb8d1ee6fb04940984dcb6d66d626cd","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"TypeError","evalue":"An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:402\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;66;03m# A prefix in the message to disambiguate between the train- and (optional) val dataloader that .fit() accepts\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 46\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m     39\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     40\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#     callbacks=callbacks, \u001b[39;00m\n\u001b[1;32m     42\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     43\u001b[0m     gradient_clip_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1031\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1031\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1060\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:110\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;129m@_no_grad_context\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_OUT_DICT]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip:\n\u001b[1;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:179\u001b[0m, in \u001b[0;36m_EvaluationLoop.setup_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dl \u001b[38;5;129;01min\u001b[39;00m combined_loader\u001b[38;5;241m.\u001b[39mflattened:\n\u001b[0;32m--> 179\u001b[0m     \u001b[43m_check_dataloader_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     dl \u001b[38;5;241m=\u001b[39m _process_dataloader(trainer, trainer_fn, stage, dl)\n\u001b[1;32m    181\u001b[0m     dataloaders\u001b[38;5;241m.\u001b[39mappend(dl)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:418\u001b[0m, in \u001b[0;36m_check_dataloader_iterable\u001b[0;34m(dataloader, source, trainer_fn)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_overridden(source\u001b[38;5;241m.\u001b[39mname, source\u001b[38;5;241m.\u001b[39minstance):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was passed to `Trainer.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdataloaders=...)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Either pass the dataloader to the `.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer_fn\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()` method OR implement\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `def \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(self):` in your LightningModule/LightningDataModule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n\u001b[0;32m--> 418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn invalid dataloader was returned from `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(source\u001b[38;5;241m.\u001b[39minstance)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataloader\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m )\n","\u001b[0;31mTypeError\u001b[0m: An invalid dataloader was returned from `PyanNet.val_dataloader()`. Found None."]}],"source":["from types import MethodType\n","from torch.optim import Adam\n","from pytorch_lightning.callbacks import (\n","    EarlyStopping,\n","    ModelCheckpoint,\n","    RichProgressBar,\n",")\n","\n","def configure_optimizers(self):\n","    return Adam(self.parameters(), lr=1e-4)\n","\n","model.configure_optimizers = MethodType(configure_optimizers, model)\n","monitor, direction = task.val_monitor\n","\n","checkpoint = ModelCheckpoint(\n","    monitor=monitor,\n","    mode=direction,\n","    save_top_k=1,\n","    every_n_epochs=1,\n","    save_last=False,\n","    save_weights_only=False,\n","    filename=\"{epoch}\",\n","    verbose=False,\n",")\n","\n","early_stopping = EarlyStopping(\n","    monitor=monitor,\n","    mode=direction,\n","    min_delta=0.0,\n","    patience=10,\n","    strict=True,\n","    verbose=False,\n",")\n","\n","callbacks = [RichProgressBar(), checkpoint, early_stopping]\n","\n","\n","from pytorch_lightning import Trainer\n","trainer = Trainer(\n","    accelerator=\"gpu\", \n","#     callbacks=callbacks, \n","    max_epochs=20,\n","    gradient_clip_val=0.5\n",")\n","\n","trainer.fit(model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1877225,"sourceId":3085190,"sourceType":"datasetVersion"},{"datasetId":4663140,"sourceId":7933012,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
